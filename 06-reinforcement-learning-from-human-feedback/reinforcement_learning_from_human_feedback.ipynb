{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d58cba3",
   "metadata": {},
   "source": [
    "# Reinforcement Learning from Human Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3d763",
   "metadata": {},
   "source": [
    "Resource: https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a64420",
   "metadata": {},
   "source": [
    "## Datasets for RL training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8b906",
   "metadata": {},
   "source": [
    "### Preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_dataset_path = \"../data/sample_preference.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "preference_data = []\n",
    "\n",
    "with open(preference_dataset_path) as f:\n",
    "    for line in f:\n",
    "        preference_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = preference_data[0]\n",
    "print(type(sample_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb4f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1[\"input_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_data[2][\"input_text\"][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"candidate_0:\\n{sample_1.get('candidate_0')}\\n\")\n",
    "print(f\"candidate_1:\\n{sample_1.get('candidate_1')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"choice: {sample_1.get('choice')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4a717",
   "metadata": {},
   "source": [
    "### Prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dataset_path = \"../data/sample_prompt.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = []\n",
    "\n",
    "with open(prompt_dataset_path) as f:\n",
    "    for line in f:\n",
    "        prompt_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0808f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the information in the prompt dataset with a better visualization\n",
    "def print_d(d):\n",
    "    for key, val in d.items():        \n",
    "        print(f\"key:{key}\\nval:{val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64031bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_d(prompt_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_d(prompt_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933558ba",
   "metadata": {},
   "source": [
    "## Tune an LLM with RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf27b0",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42800a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import (RLFH is currently in preview)\n",
    "from google_cloud_pipeline_components.preview.llm import rlhf_pipeline\n",
    "\n",
    "# Import from KubeFlow pipelines\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a path to the yaml file\n",
    "RLHF_PIPELINE_PKG_PATH = \"../data/rlhf_pipeline.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the compile function\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=rlhf_pipeline,\n",
    "    package_path=RLHF_PIPELINE_PKG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273503fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first lines of the YAML file\n",
    "!head rlhf_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebd5e2",
   "metadata": {},
   "source": [
    "### Define pipeline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b834ebc",
   "metadata": {},
   "source": [
    "```python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f56fe",
   "metadata": {},
   "source": [
    "### Choose model to be tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8c808",
   "metadata": {},
   "source": [
    "```python\n",
    "parameter_values={\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f32df0",
   "metadata": {},
   "source": [
    "### Calculate number of reward model training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf2c99",
   "metadata": {},
   "source": [
    "$$ stepsPerEpoch = \\left\\lceil \\frac{datasetSize}{batchSize} \\right\\rceil$$\n",
    "$$ trainSteps = stepsPerEpoch \\times numEpochs$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1104f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preference dataset size\n",
    "PREF_DATASET_SIZE = 3000\n",
    "\n",
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_STEPS_PER_EPOCH = math.ceil(PREF_DATASET_SIZE / BATCH_SIZE)\n",
    "print(REWARD_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7557380",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of steps in the reward model training\n",
    "reward_model_train_steps = REWARD_STEPS_PER_EPOCH * REWARD_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197aef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reward_model_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82263a",
   "metadata": {},
   "source": [
    "### Calculate number of reinforcement learning training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt dataset size\n",
    "PROMPT_DATASET_SIZE = 2000\n",
    "\n",
    "# Batch size is fixed at 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_STEPS_PER_EPOCH = math.ceil(PROMPT_DATASET_SIZE / BATCH_SIZE)\n",
    "print(RL_STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of steps in the RL training\n",
    "reinforcement_learning_train_steps = RL_STEPS_PER_EPOCH * RL_NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b47aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reinforcement_learning_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4157669b",
   "metadata": {},
   "source": [
    "### Define the instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321143f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed values for the dictionary\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 1410,\n",
    "        \"reinforcement_learning_train_steps\": 320, # results from the calculations above\n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 1.0,\n",
    "        \"kl_coeff\": 0.1, # increased to reduce reward hacking\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d1a95",
   "metadata": {},
   "source": [
    "### Train with full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699daf8b",
   "metadata": {},
   "source": [
    "```python\n",
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 10000,\n",
    "        \"reinforcement_learning_train_steps\": 10000, \n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 0.2,\n",
    "        \"kl_coeff\": 0.1,\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711a20b",
   "metadata": {},
   "source": [
    "### Set up Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import base64\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "def authenticate():\n",
    "    #Load .env\n",
    "    load_dotenv()\n",
    "    #DLAI Custom Key\n",
    "    return \"DLAI_CREDENTIALS\", \"DLAI_PROJECT\", \"gs://gcp-sc2-rlhf\"\n",
    "    \n",
    "    #Decode key and store in .JSON\n",
    "    SERVICE_ACCOUNT_KEY_STRING_B64 = os.getenv('SERVICE_ACCOUNT_KEY')\n",
    "    SERVICE_ACCOUNT_KEY_BYTES_B64 = SERVICE_ACCOUNT_KEY_STRING_B64.encode(\"ascii\")\n",
    "    SERVICE_ACCOUNT_KEY_STRING_BYTES = base64.b64decode(SERVICE_ACCOUNT_KEY_BYTES_B64)\n",
    "    SERVICE_ACCOUNT_KEY_STRING = SERVICE_ACCOUNT_KEY_STRING_BYTES.decode(\"ascii\")\n",
    "\n",
    "    SERVICE_ACCOUNT_KEY = json.loads(SERVICE_ACCOUNT_KEY_STRING)\n",
    "\n",
    "\n",
    "    # Create credentials based on key from service account\n",
    "    # Make sure your account has the roles listed in the Google Cloud Setup section\n",
    "    credentials = Credentials.from_service_account_info(\n",
    "        SERVICE_ACCOUNT_KEY,\n",
    "        scopes=['https://www.googleapis.com/auth/cloud-platform'])\n",
    "\n",
    "    if credentials.expired:\n",
    "        credentials.refresh(Request())\n",
    "    \n",
    "    #Set project ID according to environment variable    \n",
    "    PROJECT_ID = os.getenv('PROJECT_ID')\n",
    "    STAGING_BUCKET = os.getenv('STAGING_BUCKET')# 'gs://gcp-sc2-rlhf-staging'\n",
    "    \n",
    "    return credentials, PROJECT_ID, STAGING_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate in utils\n",
    "credentials, PROJECT_ID, STAGING_BUCKET = authenticate()\n",
    "\n",
    "# RLFH pipeline is available in this region\n",
    "REGION = \"europe-west4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e883a",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33574563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project = PROJECT_ID,\n",
    "    location = REGION,\n",
    "    credentials = credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the path for the YAML file\n",
    "RLHF_PIPELINE_PKG_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a7b77",
   "metadata": {},
   "source": [
    "### Create and run the pipeline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42528d5",
   "metadata": {},
   "source": [
    "```Python\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"tutorial-rlhf-tuning\",\n",
    "    pipeline_root=STAGING_BUCKET,\n",
    "    template_path=RLHF_PIPELINE_PKG_PATH,\n",
    "    parameter_values=parameter_values)\n",
    "```\n",
    "- To run the pipeline job:\n",
    "\n",
    "```Python\n",
    "job.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8480c96",
   "metadata": {},
   "source": [
    "## Evaluate tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040f441",
   "metadata": {},
   "source": [
    "### Check Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = %env PORT1\n",
    "%tensorboard --logdir reward-logs --port $port --bind_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what this directory has\n",
    "%ls reward-logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fef223",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = %env PORT2\n",
    "%tensorboard --logdir reinforcer-logs --port $port --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = %env PORT3\n",
    "%tensorboard --logdir reinforcer-fulldata-logs --port $port --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values={\n",
    "        \"preference_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/summarize_from_feedback_tfds/comparisons/train/*.jsonl\",\n",
    "        \"prompt_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/train/*.jsonl\",\n",
    "        \"eval_dataset\": \\\n",
    "    \"gs://vertex-ai/generative-ai/rlhf/text_small/reddit_tfds/val/*.jsonl\",\n",
    "        \"large_model_reference\": \"llama-2-7b\",\n",
    "        \"reward_model_train_steps\": 1410,\n",
    "        \"reinforcement_learning_train_steps\": 320,\n",
    "        \"reward_model_learning_rate_multiplier\": 1.0,\n",
    "        \"reinforcement_learning_rate_multiplier\": 1.0,\n",
    "        \"kl_coeff\": 0.1,\n",
    "        \"instruction\":\\\n",
    "    \"Summarize in less than 50 words\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd025bf",
   "metadata": {},
   "source": [
    "### Evaluate tuned and untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e17cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tuned_path = \"../data/eval_results_tuned.jsonl\"\n",
    "\n",
    "eval_data_tuned = []\n",
    "\n",
    "with open(eval_tuned_path) as f:\n",
    "    for line in f:\n",
    "        eval_data_tuned.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_d(d, indent=0):\n",
    "    for key, val in d.items():\n",
    "        indentation = \"  \" * indent\n",
    "        print(f\"{indentation}\" + \"-\"*50)\n",
    "        print(f\"{indentation}key:{key}\\n\")\n",
    "        if isinstance(val, dict):\n",
    "            print(f\"{indentation}val\")\n",
    "            print_d(val,indent=indent+1)\n",
    "        else:\n",
    "            print(f\"{indentation}val:{val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb820b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the result produced by the tuned model\n",
    "print_d(eval_data_tuned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_untuned_path = \"../data/eval_results_untuned.jsonl\"\n",
    "\n",
    "eval_data_untuned = []\n",
    "\n",
    "with open(eval_untuned_path) as f:\n",
    "    for line in f:\n",
    "        eval_data_untuned.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a17662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the result produced by the untuned model\n",
    "print_d(eval_data_untuned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c896e68",
   "metadata": {},
   "source": [
    "### Explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298331d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the prompts\n",
    "prompts = [sample['inputs']['inputs_pretokenized']\n",
    "           for sample in eval_data_tuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05465fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completions from the untuned model\n",
    "untuned_completions = [sample['prediction']\n",
    "                       for sample in eval_data_untuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completions from the tuned model\n",
    "tuned_completions = [sample['prediction']\n",
    "                     for sample in eval_data_tuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a60876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3028dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    data={'prompt': prompts,\n",
    "          'base_model':untuned_completions,\n",
    "          'tuned_model': tuned_completions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
